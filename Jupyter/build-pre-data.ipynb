{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# 2017-10-05 - подготовка данных для анализа\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys,os,datetime\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import functools\n",
    "#import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn.metrics as skm\n",
    "import pymorphy2, nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dftrain, dftest = pd.read_csv(\"../Data/train_task1_latest.csv\"), pd.read_csv(\"../Data/test_task1_latest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119398, 5),\n",
       " (74294, 4),\n",
       " ['paragraph_id', 'question_id', 'paragraph', 'question', 'target'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.shape, dftest.shape, dftrain.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-06 15:18:21.209574\n",
      "\t2017-10-06 15:18:21.330623 train 0\n",
      "\t2017-10-06 15:37:45.825226 train 10000\n",
      "\t2017-10-06 15:57:13.930638 train 20000\n",
      "\t2017-10-06 16:16:49.978047 train 30000\n",
      "\t2017-10-06 16:37:28.637745 train 40000\n",
      "\t2017-10-06 16:59:30.374890 train 50000\n",
      "\t2017-10-06 17:22:20.332750 train 60000\n",
      "\t2017-10-06 17:46:02.383362 train 70000\n",
      "\t2017-10-06 18:11:09.675297 train 80000\n",
      "\t2017-10-06 18:37:18.687798 train 90000\n",
      "\t2017-10-06 19:04:21.130113 train 100000\n",
      "\t2017-10-06 19:32:24.467346 train 110000\n",
      "\t2017-10-06 19:59:58.886025 test 0\n",
      "\t2017-10-06 20:17:50.915542 test 10000\n",
      "\t2017-10-06 20:36:52.412589 test 20000\n",
      "\t2017-10-06 20:57:44.436715 test 30000\n",
      "\t2017-10-06 21:18:50.088618 test 40000\n",
      "\t2017-10-06 21:40:57.847687 test 50000\n",
      "\t2017-10-06 22:04:32.849180 test 60000\n",
      "\t2017-10-06 22:29:40.339460 test 70000\n",
      "2017-10-06 22:40:55.517930\n"
     ]
    }
   ],
   "source": [
    "print datetime.datetime.now()\n",
    "\n",
    "def prelemming (ttext) :\n",
    "    tttext  = ttext.decode('utf-8')\n",
    "    xx = nltk.word_tokenize(tttext);\n",
    "    xx = [mm2.parse(tt)[0].normal_form.encode('utf-8') for tt in xx]\n",
    "    tttext = ' '.join(xx) \n",
    "    return(tttext)\n",
    "\n",
    "def onlyX (ttext, notX={'PREP','CONJ','PRCL','INTJ'}) :\n",
    "    tttext  = ttext.decode('utf-8') if len(ttext)>0 else ' '\n",
    "    xx = nltk.word_tokenize(tttext);\n",
    "    xx = [tt.encode('utf-8') for tt in xx if mm2.parse(tt)[0].tag.POS not in notX]\n",
    "    ##print(ttext,xx)\n",
    "    tttext = ' '.join(xx)\n",
    "    return(tttext)\n",
    "\n",
    "def notstop (ttext, stopwords) :\n",
    "    tttext  = ttext.decode('utf-8')\n",
    "    xx = nltk.word_tokenize(tttext);\n",
    "    xx = [tt.encode('utf-8') for tt in xx if tt not in stopwords ]\n",
    "    tttext = ' '.join(xx) \n",
    "    return(tttext)\n",
    "\n",
    "stoprus = stoprus = nltk.corpus.stopwords.words('russian')\n",
    "\n",
    "mm2 = pymorphy2.MorphAnalyzer()\n",
    "for name, df, newfile in [('train', dftrain,'../Work/train_task1_lemma.csv'), ('test', dftest,'../Work/test_task1_lemma.csv')]:\n",
    "    \n",
    "    dfnew = df.copy()\n",
    "    for index, row in dfnew.iterrows() : #tqdm.tqdm(df.iterrows(), total=df.shape[0], desc=\"build features for \" + name):    \n",
    "        if index%10000==0 : print '\\t',datetime.datetime.now(), name, index\n",
    "        parL  =  prelemming(row.paragraph)\n",
    "        queL  =  prelemming(row.question)\n",
    "        parLS =  notstop(parL,stoprus)\n",
    "        queLS =  notstop(queL,stoprus)\n",
    "        dfnew.loc[index, 'paragraphL']    = parL\n",
    "        dfnew.loc[index, 'questionL']     = queL\n",
    "        dfnew.loc[index, 'paragraphLS']   = parLS\n",
    "        dfnew.loc[index, 'questionLS']    = queLS\n",
    "        dfnew.loc[index, 'paragraphLX']   = onlyX(parL)\n",
    "        dfnew.loc[index, 'questionLX']    = onlyX(queL)\n",
    "        dfnew.loc[index, 'paragraphLSX']  = onlyX(parLS)\n",
    "        dfnew.loc[index, 'questionLSX']   = onlyX(queLS)\n",
    "        \n",
    "    dfnew.to_csv(newfile,index=False)\n",
    "    \n",
    "print datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stoprus = stoprus = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boba/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:1: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, False, True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'иметь' in stoprus, 'в' in stoprus, u'в' in stoprus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "print len(stoprus)\n",
    "#for tt in stoprus : print tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
